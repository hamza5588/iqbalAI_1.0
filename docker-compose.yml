services:
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./static:/app/static
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl:ro 
    depends_on:
      flask_app1:
        condition: service_healthy
      flask_app2:
        condition: service_healthy
      flask_app3:
        condition: service_healthy
      flask_app4:
        condition: service_healthy
    networks:
      - app_network

  # PRIMARY - Handles ALL writes (POST, PUT, DELETE, PATCH)
  flask_app1:
    build:
      context: .
      dockerfile: Dockerfile
    expose:
      - "5000"
    environment:
      - FLASK_APP=run.py
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - OPENBLAS_NUM_THREADS=2
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - RAYON_NUM_THREADS=2
      - TOKENIZERS_PARALLELISM=false
      - TQDM_DISABLE=1
      - DB_MODE=primary
      - INSTANCE_ROLE=primary
      - GOOGLE_CLIENT_ID=507995986306-qcdrhrrt3d71la4pkrf7lt1b2tvuusqm.apps.googleusercontent.com
      - GROQ_CLIENT_ID=your-groq-client-id
      - GROQ_CLIENT_SECRET=your-groq-client-secret
      - GROQ_API_KEY=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
      - NOMIC_APIC_KEY=nk-7Ad201NonNkEv_pYdRwb-EkNjf84mVLW205ihoE7RyU
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:3b
      - OLLAMA_TIMEOUT=600
    volumes:
      - app_data:/app/instance  # Read-write access
      - .:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
     - ollama
    deploy:
      resources:
        limits:
          cpus: '3'
          memory: 6G
        reservations:
          cpus: '2'
          memory: 4G
    networks:
      - app_network

  # REPLICA 1 - Read-only
  flask_app2:
    build:
      context: .
      dockerfile: Dockerfile
    expose:
      - "5000"
    environment:
      - FLASK_APP=run.py
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - OPENBLAS_NUM_THREADS=2
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - RAYON_NUM_THREADS=2
      - TOKENIZERS_PARALLELISM=false
      - TQDM_DISABLE=1
      - DB_MODE=readonly
      - INSTANCE_ROLE=replica
      - GOOGLE_CLIENT_ID=your-google-client-id
      - GROQ_CLIENT_ID=your-groq-client-id
      - GROQ_CLIENT_SECRET=your-groq-client-secret
      - GROQ_API_KEY=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
      - NOMIC_APIC_KEY=nk-7Ad201NonNkEv_pYdRwb-EkNjf84mVLW205ihoE7RyU
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:3b
      - OLLAMA_TIMEOUT=600
    volumes:
      - app_data:/app/instance:ro  # Read-only mount
      - .:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
     - ollama
     - flask_app1
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - app_network

  # REPLICA 2 - Read-only
  flask_app3:
    build:
      context: .
      dockerfile: Dockerfile
    expose:
      - "5000"
    environment:
      - FLASK_APP=run.py
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - OPENBLAS_NUM_THREADS=2
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - RAYON_NUM_THREADS=2
      - TOKENIZERS_PARALLELISM=false
      - TQDM_DISABLE=1
      - DB_MODE=readonly
      - INSTANCE_ROLE=replica
      - GOOGLE_CLIENT_ID=your-google-client-id
      - GROQ_CLIENT_ID=your-groq-client-id
      - GROQ_CLIENT_SECRET=your-groq-client-secret
      - GROQ_API_KEY=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
      - NOMIC_APIC_KEY=nk-7Ad201NonNkEv_pYdRwb-EkNjf84mVLW205ihoE7RyU
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:3b
      - OLLAMA_TIMEOUT=600
    volumes:
      - app_data:/app/instance:ro  # Read-only mount
      - .:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
    - ollama
    - flask_app1
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - app_network

  # REPLICA 3 - Read-only
  flask_app4:
    build:
      context: .
      dockerfile: Dockerfile
    expose:
      - "5000"
    environment:
      - FLASK_APP=run.py
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - OPENBLAS_NUM_THREADS=2
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - RAYON_NUM_THREADS=2
      - TOKENIZERS_PARALLELISM=false
      - TQDM_DISABLE=1
      - DB_MODE=readonly
      - INSTANCE_ROLE=replica
      - GOOGLE_CLIENT_ID=your-google-client-id
      - GROQ_CLIENT_ID=your-groq-client-id
      - GROQ_CLIENT_SECRET=your-groq-client-secret
      - GROQ_API_KEY=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
      - NOMIC_APIC_KEY=nk-7Ad201NonNkEv_pYdRwb-EkNjf84mVLW205ihoE7RyU
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:3b
      - OLLAMA_TIMEOUT=600
    volumes:
      - app_data:/app/instance:ro  # Read-only mount
      - .:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
     - ollama
     - flask_app1
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - app_network

  ollama:
    image: ollama/ollama:latest
    expose:
      - "11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      # Optimized for 16 CPU cores
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_NUM_THREAD=12
      - OLLAMA_KEEP_ALIVE=15m
    entrypoint: ["/bin/sh", "-c", "ollama serve & sleep 5 && ollama pull qwen2.5:3b && wait"]
    deploy:
      resources:
        limits:
          cpus: '12'
          memory: 40G
        reservations:
          cpus: '8'
          memory: 20G
    networks:
      - app_network
    restart: unless-stopped

volumes:
  app_data:  # Shared volume for SQLite database
  ollama_data:

networks:
  app_network:
    driver: bridge